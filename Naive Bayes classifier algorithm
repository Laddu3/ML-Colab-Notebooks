{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Naive Bayes classifier algorithm","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO4sikFNKYjmRqXOfFqHtIP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"fsdDAjblVQCV","executionInfo":{"status":"error","timestamp":1620925994970,"user_tz":-330,"elapsed":2559,"user":{"displayName":"Harsha Reddy","photoUrl":"https://lh3.googleusercontent.com/-K1dSGZ93uAM/AAAAAAAAAAI/AAAAAAAAGlA/GrleEG6tHvw/s64/photo.jpg","userId":"12459592879607819367"}},"outputId":"1f35e912-ecd1-49f6-9dc1-b8350c85b153","colab":{"base_uri":"https://localhost:8080/","height":354}},"source":["# Importing the libraries  \n","import numpy as nm  \n","import matplotlib.pyplot as mtp  \n","import pandas as pd  \n","  \n","# Importing the dataset  \n","dataset = pd.read_csv('user_data.csv')  \n","x = dataset.iloc[:, [2, 3]].values  \n","y = dataset.iloc[:, 4].values  \n","\n","# Splitting the dataset into the Training set and Test set  \n","from sklearn.model_selection import train_test_split  \n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)  \n","  \n","# Feature Scaling  \n","from sklearn.preprocessing import StandardScaler  \n","sc = StandardScaler()  \n","x_train = sc.fit_transform(x_train)  \n","x_test = sc.transform(x_test)  "],"execution_count":2,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-bba84f526ea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    698\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[1;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Computers/Tablets & Networking,Tablets & eBook Readers,Computers & Tablets,Tablets,All Tablets'"]}]},{"cell_type":"code","metadata":{"id":"x-zh4wv2Vlm2","executionInfo":{"status":"aborted","timestamp":1620925994963,"user_tz":-330,"elapsed":2542,"user":{"displayName":"Harsha Reddy","photoUrl":"https://lh3.googleusercontent.com/-K1dSGZ93uAM/AAAAAAAAAAI/AAAAAAAAGlA/GrleEG6tHvw/s64/photo.jpg","userId":"12459592879607819367"}}},"source":["# Fitting Naive Bayes to the Training set  \n","from sklearn.naive_bayes import GaussianNB  \n","classifier = GaussianNB()  \n","classifier.fit(x_train, y_train)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gaKSZsAiVlpd","executionInfo":{"status":"aborted","timestamp":1620925994965,"user_tz":-330,"elapsed":2538,"user":{"displayName":"Harsha Reddy","photoUrl":"https://lh3.googleusercontent.com/-K1dSGZ93uAM/AAAAAAAAAAI/AAAAAAAAGlA/GrleEG6tHvw/s64/photo.jpg","userId":"12459592879607819367"}}},"source":["# Predicting the Test set results  \n","y_pred = classifier.predict(x_test)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kwNVLn7eVlsG","executionInfo":{"status":"aborted","timestamp":1620925994967,"user_tz":-330,"elapsed":2533,"user":{"displayName":"Harsha Reddy","photoUrl":"https://lh3.googleusercontent.com/-K1dSGZ93uAM/AAAAAAAAAAI/AAAAAAAAGlA/GrleEG6tHvw/s64/photo.jpg","userId":"12459592879607819367"}}},"source":["# Making the Confusion Matrix  \n","from sklearn.metrics import confusion_matrix  \n","cm = confusion_matrix(y_test, y_pred)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Rv6k9dIVlun","executionInfo":{"status":"aborted","timestamp":1620925994968,"user_tz":-330,"elapsed":2528,"user":{"displayName":"Harsha Reddy","photoUrl":"https://lh3.googleusercontent.com/-K1dSGZ93uAM/AAAAAAAAAAI/AAAAAAAAGlA/GrleEG6tHvw/s64/photo.jpg","userId":"12459592879607819367"}}},"source":["# Visualising the Training set results  \n","from matplotlib.colors import ListedColormap  \n","x_set, y_set = x_train, y_train  \n","X1, X2 = nm.meshgrid(nm.arange(start = x_set[:, 0].min() - 1, stop = x_set[:, 0].max() + 1, step = 0.01),  \n","                     nm.arange(start = x_set[:, 1].min() - 1, stop = x_set[:, 1].max() + 1, step = 0.01))  \n","mtp.contourf(X1, X2, classifier.predict(nm.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),  \n","             alpha = 0.75, cmap = ListedColormap(('purple', 'green')))  \n","mtp.xlim(X1.min(), X1.max())  \n","mtp.ylim(X2.min(), X2.max())  \n","for i, j in enumerate(nm.unique(y_set)):  \n","    mtp.scatter(x_set[y_set == j, 0], x_set[y_set == j, 1],  \n","                c = ListedColormap(('purple', 'green'))(i), label = j)  \n","mtp.title('Naive Bayes (Training set)')  \n","mtp.xlabel('Age')  \n","mtp.ylabel('Estimated Salary')  \n","mtp.legend()  \n","mtp.show()  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cf6kIhnlVlyA","executionInfo":{"status":"aborted","timestamp":1620925994969,"user_tz":-330,"elapsed":2523,"user":{"displayName":"Harsha Reddy","photoUrl":"https://lh3.googleusercontent.com/-K1dSGZ93uAM/AAAAAAAAAAI/AAAAAAAAGlA/GrleEG6tHvw/s64/photo.jpg","userId":"12459592879607819367"}}},"source":["# Visualising the Test set results  \n","from matplotlib.colors import ListedColormap  \n","x_set, y_set = x_test, y_test  \n","X1, X2 = nm.meshgrid(nm.arange(start = x_set[:, 0].min() - 1, stop = x_set[:, 0].max() + 1, step = 0.01),  \n","                     nm.arange(start = x_set[:, 1].min() - 1, stop = x_set[:, 1].max() + 1, step = 0.01))  \n","mtp.contourf(X1, X2, classifier.predict(nm.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),  \n","             alpha = 0.75, cmap = ListedColormap(('purple', 'green')))  \n","mtp.xlim(X1.min(), X1.max())  \n","mtp.ylim(X2.min(), X2.max())  \n","for i, j in enumerate(nm.unique(y_set)):  \n","    mtp.scatter(x_set[y_set == j, 0], x_set[y_set == j, 1],  \n","                c = ListedColormap(('purple', 'green'))(i), label = j)  \n","mtp.title('Naive Bayes (test set)')  \n","mtp.xlabel('Age')  \n","mtp.ylabel('Estimated Salary')  \n","mtp.legend()  \n","mtp.show() "],"execution_count":null,"outputs":[]}]}